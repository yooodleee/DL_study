import argparse
import os
import traceback
import warnings
from typing import TYPE_CHECKING, List, Optional, Tuple, Union

import numpy as np
import torch
import tqdm

from .audio import (
    FRAMES_PER_SECOND,
    HOP_LENGTH,
    N_FRAMES,
    N_SAMPLES,
    log_mel_spectrogram,
    pad_or_trim)

from .decoding import DecodingOptions, DecodingResult
from .timing import add_word_timestapms
from .tokenizer import LANGUAGES, TO_LANGUAGE_CODE, get_tokenizer
from .utils import (
    exact_div,
    format_timestamp,
    get_end,
    get_writer,
    make_safe,
    optional_float,
    optional_int,
    str2bool)

if TYPE_CHECKING:
    from .model import Whisper


def transcribe(
        model: "Whisper",
        audio: Union[str, np.ndarray, torch.Tensor],
        *,
        verbose: Optional[bool] = None,
        temperature: Union[float, Tuple[float, ...]] = \
                        (0.0, 0.2, 0.4, 0.6, 0.8, 1.0),
        compression_ratio_threashold: Optional[float] = 2.4,
        logprob_threshold: Optional[float] = -1.0,
        no_speech_threshold: Optional[float] = 0.6,
        condition_on_previous_text: bool = True,
        initial_prompt: Optional[str] = None,
        carry_initial_prompt: bool = False,
        word_timestamps: bool = False,
        prepend_punctuations: str = "\"'“¿([{-",
        append_punctuations: str = "\"'.。,，!！?？:：”)]}、",
        clip_timestamps: Union[str, List[float]] = 0,
        hallucination_silence_threshold: Optional[float] = None,
        **decode_options):
    """
    Transcribe an audion file using Whisper

    Parameters:
        model: Whisper
            The Whisper model instance

        audio: Union[str, np.ndarray, torch.Tensor]
            The path to the audio file to open, or the audio waveform

        verbose: bool
            Whether to display the text being decoded to the console. If True,
                displays all the details, If False, displays minimal details.
                If None, does not display anything

        temperature: Union[float, Tuple[float, ...]]
            Temperature for sampling. It can be a tuple of temperatures, which
                will be successively used upon failures according to either
                `compression_ratio_threshold` or `logprob_threshold`.

        compression_ratio_threshold: float
            If the gzip compression ratio is above this value, treat as failed

        logprob_threshold: float
            If the average log probability over sampled tokens is below this
                value, treat as failed
        
        no_speech_threshold: float
            If the no_speech probability is higher than this value AND the 
                average log probability over sampled tokens is below 
                `logprob_threshold`, consider the segment as silent

        condition_on_previous_text: bool
            if True, the previous output of the model is provided as a prompt
                for the next window; disabling may make the text inconsistent
                across windows, but the model becomes less prone to getting
                stuck in a failure loop, such as repetition looping or
                timestamps going out of sync.

        word_timestamps: bool
            Extract word-level timestamps using the cross-attention pattern
                and dynamic time warping, and include the timestamps for each
                word in each segment.

        prepend_punctuations: str
            If word_timestamps is True, merge these punctuation symbols with 
                the next word

        append_punctuations: str
            If word_timestamps is True,, merge these punctuation symbols with
                the previous word

        initial_prompt: Optional[str]
            Optional text to provide as a prompt for the first window. 
                This can be used to provide, or "prompt-engineer" a context
                transcription, e.g. custom vocabularies or proper nouns to 
                make it more likely to predict those word correctly.

        caarry_initial_prompt: bool
            If carry_initial_prompt is True, `initial_prompt` is prepended to 
                the prompt of each internal `decode()` call. If there is not
                enough context space at the start of the prompt, it is 
                left-sliced to make space.
        
        decode_options: dict
            Keyword arguments to construct `DecodingOptions` instances

        clip_timestamps: Union[str, List[float]]
            Comma-separated list start, end, start, end,... timestamps 
                (in seconds) of clips to process. The last end timestamp
                defaults to the end of the file.

        hallucination_silence_threshold: Optional[float]
            When word_timestamps is True, skip silent periods longer than 
                this threshold (in seconds) when a possible hallucination is
                detected

    Returns:
        A dictionary containing the resulting text ("text") and segment-level
            details ("segments"), and the spoken language ("language"), which 
            is detected when `decode_options["language"]` is None.
    """
    